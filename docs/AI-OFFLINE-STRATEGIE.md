# Offline-AI-Strategie â€“ gÃ¤stefotos.com

> Stand: Juli 2025 | Status: Lernendes Cache-System implementiert âœ…

---

## 1. Problemstellung

Bei Events (Hochzeiten, Firmenfeiern) kann die Internetverbindung instabil oder gar nicht vorhanden sein. Die AI-Features der App (Text-VorschlÃ¤ge, Chat-Bot) dÃ¼rfen dadurch nicht ausfallen.

### Hardware-RealitÃ¤t
| Szenario | Hardware | GPU | Internet | AI-FÃ¤higkeit |
|----------|----------|-----|----------|-------------|
| **Cloud-Server** | Ryzen 9 5950X, 128GB RAM, NVMe | Keine | âœ… Stabil | Cloud-AI + Ollama mÃ¶glich |
| **Event-Terminal (NUC)** | Mini-PC, 8-16GB RAM | Keine | âŒ Instabil | Nur Cache + Fallbacks |
| **GÃ¤ste-Smartphones** | Diverse | - | âŒ Event-WLAN | Ãœber Terminal/Server |

### Fazit
- **Text-AI** (VorschlÃ¤ge, Chat): Offline via Cache mÃ¶glich âœ…
- **Bild-AI** (Face-Switch, Style Transfer): Cloud-abhÃ¤ngig, kein Offline âŒ
- **Gesichtserkennung**: Lokales Modell denkbar, aber aufwÃ¤ndig âš ï¸

---

## 2. Lernendes AI-Cache-System

### Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Request                           â”‚
â”‚                      â”‚                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚              â”‚  Cache prÃ¼fen â”‚                       â”‚
â”‚              â”‚  (Redis)      â”‚                       â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                      â”‚                               â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚            â”‚                   â”‚                     â”‚
â”‚      Cache-Hit           Cache-Miss                  â”‚
â”‚        â”‚                       â”‚                     â”‚
â”‚   Sofortige              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”               â”‚
â”‚   Antwort âœ…             â”‚  Online?  â”‚               â”‚
â”‚   (< 1ms)                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”               â”‚
â”‚                          â”‚           â”‚               â”‚
â”‚                       Online     Offline             â”‚
â”‚                          â”‚           â”‚               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  Statischer         â”‚
â”‚                    â”‚ AI-API    â”‚  Fallback            â”‚
â”‚                    â”‚ aufrufen  â”‚  (Hardcoded)         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                          â”‚                           â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                     â”‚
â”‚                    â”‚ Antwort   â”‚                     â”‚
â”‚                    â”‚ cachen    â”‚                     â”‚
â”‚                    â”‚ (30 Tage) â”‚                     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                     â”‚
â”‚              â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â”‚
â”‚              DAS SYSTEM LERNT:                       â”‚
â”‚              Jede Anfrage fÃ¼llt                      â”‚
â”‚              den Cache weiter                        â”‚
â”‚              â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementierte Dateien

| Datei | Funktion |
|-------|----------|
| `src/services/cache/aiCache.ts` | Kern-Cache-System mit Get/Set/Stats/WarmUp/Clear |
| `src/lib/groq.ts` | 6 AI-Funktionen mit Cache-Integration |
| `src/routes/ai.ts` | Admin-Endpoints fÃ¼r Cache-Management |
| `src/services/cache/redis.ts` | Redis-Client (Basis-Infrastruktur) |

### Gecachte Features

| Feature | Cache-Key-Parameter | TTL | Offline-Fallback |
|---------|-------------------|-----|-----------------|
| `suggest-albums` | eventType, eventTitle | 30 Tage | Hardcoded Album-Namen pro Event-Typ |
| `suggest-description` | eventType, eventTitle, eventDate | 30 Tage | Generischer Willkommenstext |
| `suggest-invitation` | eventType, eventTitle, hostName | 30 Tage | Generischer Einladungstext |
| `suggest-challenges` | eventType | 30 Tage | Hardcoded Challenges pro Event-Typ |
| `suggest-guestbook` | eventType, eventTitle | 30 Tage | Generische GÃ¤stebuch-Nachricht |
| `suggest-colors` | eventType, keywords, mood | 30 Tage | Hardcoded Farbschemata pro Event-Typ |
| `chat` | Nachrichteninhalt | 7 Tage | FAQ-Keywords + generische Antwort |

### Cache-Key-Generierung

Keys werden deterministisch aus Feature + sortierten Parametern generiert:
```
ai:cache:{feature}:{md5_hash_der_parameter}
```

Beispiel: `ai:cache:suggest-albums:a1b2c3d4e5f6`

Dadurch liefern identische Anfragen immer denselben Cache-Eintrag.

---

## 3. Warm-Up System

### Automatisches VorwÃ¤rmen

Vor einem Event kann der Cache aufgewÃ¤rmt werden, sodass hÃ¤ufige Anfragen bereits gecacht sind:

```bash
# API-Aufruf: Cache aufwÃ¤rmen
POST /api/ai/cache/warm-up
Body: { "eventTypes": ["wedding", "party"] }
```

### Was wird vorgeladen?

FÃ¼r jeden Event-Typ werden generiert:
- Album-VorschlÃ¤ge
- Challenge-Ideen  
- Farbschemata
- Beschreibungen (mit hÃ¤ufigen Titeln: "Unsere Hochzeit", "Feier", etc.)
- GÃ¤stebuch-Nachrichten
- Einladungstexte

### HÃ¤ufige Event-Titel pro Typ

| Event-Typ | Vorgeladene Titel |
|-----------|------------------|
| wedding | "Unsere Hochzeit", "Hochzeit" |
| party | "Feier", "Party" |
| business | "Firmenfeier", "Teambuilding", "Konferenz" |
| family | "Familientreffen", "Familienfeier" |
| milestone | "Geburtstag", "JubilÃ¤um" |
| custom | "Event", "Veranstaltung" |

---

## 4. Admin-API-Endpoints

| Endpoint | Methode | Beschreibung |
|----------|---------|-------------|
| `/api/ai/cache/stats` | GET | Cache-Statistiken (EintrÃ¤ge, Hits, pro Feature) |
| `/api/ai/cache/warm-up` | POST | Cache aufwÃ¤rmen (optional: eventTypes Array) |
| `/api/ai/cache` | DELETE | Gesamten AI-Cache lÃ¶schen |
| `/api/ai/cache/online-status` | GET | PrÃ¼ft ob AI-Provider erreichbar sind |

### Beispiel-Antwort `/api/ai/cache/stats`

```json
{
  "stats": {
    "totalEntries": 42,
    "totalHits": 156,
    "features": {
      "suggest-albums": { "entries": 8, "hits": 34 },
      "suggest-challenges": { "entries": 6, "hits": 28 },
      "suggest-colors": { "entries": 12, "hits": 45 }
    }
  },
  "entries": {
    "suggest-albums": 8,
    "suggest-description": 6,
    "suggest-invitation": 5,
    "suggest-challenges": 6,
    "suggest-guestbook": 5,
    "suggest-colors": 12,
    "chat": 3
  },
  "aiOnline": true,
  "offlineReady": true
}
```

---

## 5. Offline-Ablauf am Event

### Vorbereitung (mit Internet)

1. **Event erstellen** â†’ AI-VorschlÃ¤ge werden automatisch gecacht
2. **Warm-Up ausfÃ¼hren** â†’ HÃ¤ufige Anfragen vorladen
3. **Redis-Datenbank** â†’ EnthÃ¤lt alle gecachten Antworten

### WÃ¤hrend des Events (ohne Internet)

1. **Gast Ã¶ffnet App** â†’ Statische Assets aus Service Worker
2. **AI-Feature angefragt** â†’ Cache-Hit â†’ Sofortige Antwort
3. **Cache-Miss** â†’ Statischer Fallback â†’ Funktionale, aber generische Antwort
4. **Bild-AI** â†’ Nicht verfÃ¼gbar, Hinweis anzeigen

### Nach dem Event (mit Internet)

1. **Neue Anfragen** â†’ Werden an Cloud-AI gesendet
2. **Ergebnisse** â†’ Automatisch gecacht fÃ¼r zukÃ¼nftige Events
3. **Cache wÃ¤chst** â†’ System wird mit jeder Nutzung besser

---

## 6. Resilience-Stufen

| Stufe | Internet | AI-QualitÃ¤t | VerfÃ¼gbare Features |
|-------|----------|-------------|-------------------|
| ğŸŸ¢ **Voll Online** | Stabil | Beste | Alle Features inkl. Bild-AI |
| ğŸŸ¡ **Cache-Modus** | Instabil | Gut (gecacht) | Text-AI aus Cache, Bild-AI instabil |
| ğŸŸ  **Offline + Cache** | Keins | Gut (gecacht) | Nur gecachte Text-AI |
| ğŸ”´ **Offline + Leer** | Keins | Basisfunktional | Nur statische Fallbacks |

---

## 7. Zukunft: Ollama-Integration

### Dedizierter Server (Ryzen 9 5950X)

Ollama kann als lokaler LLM-Server auf dem dedizierten Server laufen:

```
NUC (Event) â†’ [Internet?] â†’ Dedizierter Server (Ollama)
                                    â†“ Fallback
                              Cloud-Provider (Groq/OpenAI)
```

**Vorteile:**
- Volle Kontrolle Ã¼ber die Modelle
- Keine API-Kosten fÃ¼r Text-AI
- Datenschutz (keine Daten an Dritte)
- OpenAI-kompatible API â†’ minimaler Code-Aufwand

**Empfohlene Modelle:**
| Modell | RAM-Bedarf | QualitÃ¤t | Geschwindigkeit |
|--------|-----------|----------|----------------|
| Llama 3.1 8B | ~8 GB | Gut | Sehr schnell |
| Llama 3.1 70B | ~40 GB | Sehr gut | Mittel |
| Mistral 7B | ~6 GB | Gut | Sehr schnell |

**Status:** Geplant (TODO #36)

---

## 8. Was NICHT offline funktioniert

| Feature | Grund | Alternative |
|---------|-------|------------|
| Face Switch | Cloud-GPU erforderlich | Hinweis: "Nur mit Internet verfÃ¼gbar" |
| Background Removal | Cloud-GPU erforderlich | Einfache lokale LÃ¶sung mÃ¶glich |
| Style Transfer | Stability AI / Replicate API | Vorher generierte Styles cachen |
| AI Oldify / Cartoon | Cloud-GPU erforderlich | Keine |
| Highlight Reel | Video-Verarbeitung in Cloud | Keine |
| Face Search | ML-Modell lokal mÃ¶glich | Lokales Modell (TBD) |

---

## 9. Metriken & Monitoring

Das Cache-System trackt automatisch:

- **Hit Count pro Eintrag** â†’ Beliebte Anfragen identifizieren
- **Globale Hit-Statistiken** â†’ Cache-Effizienz messen
- **Entry Count pro Feature** â†’ Cache-Abdeckung Ã¼berwachen
- **Online-Status** â†’ AI-VerfÃ¼gbarkeit in Echtzeit

### KPIs

| Metrik | Ziel | Beschreibung |
|--------|------|-------------|
| Cache-Hit-Rate | > 70% | Anteil der Anfragen aus dem Cache |
| Offline-Abdeckung | > 90% | Gecachte Event-Typen |
| Warm-Up-VollstÃ¤ndigkeit | 100% | Alle 6 Features pro Event-Typ |

---

## 10. Zusammenfassung

```
âœ… Implementiert:
   - Lernendes AI-Cache-System (Redis-basiert)
   - 6 Text-AI-Features mit Cache-Integration
   - Warm-Up-System fÃ¼r Event-Vorbereitung
   - Admin-API fÃ¼r Cache-Verwaltung
   - Online-Status-PrÃ¼fung
   - Statische Fallbacks fÃ¼r alle Features
   - Hit-Tracking und Statistiken

â³ Geplant:
   - Ollama auf dediziertem Server
   - Admin-Dashboard UI fÃ¼r Cache-Verwaltung
   - Automatisches Warm-Up bei Event-Erstellung
   - Service Worker fÃ¼r komplette Offline-PWA
```
